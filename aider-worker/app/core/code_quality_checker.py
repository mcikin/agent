"""
Code quality checker for generated Python tasks.

This module provides linting and quality analysis for Python code generated by the LLM
to ensure production-ready code quality.
"""

import ast
import re
from typing import Dict, List, Any, Optional
from dataclasses import dataclass


@dataclass
class CodeQualityIssue:
    """Represents a code quality issue found in generated code."""
    severity: str  # 'error', 'warning', 'info'
    category: str  # 'syntax', 'security', 'performance', 'style', 'logic'
    message: str
    line_number: Optional[int] = None
    suggestion: Optional[str] = None


class CodeQualityChecker:
    """Analyzes Python code quality for generated tasks."""

    @staticmethod
    def analyze_python_code(code: str, task_id: str = "") -> List[CodeQualityIssue]:
        """
        Analyze Python code and return quality issues.

        Args:
            code: The Python code to analyze
            task_id: Task identifier for context

        Returns:
            List of CodeQualityIssue objects
        """
        issues = []

        # Basic syntax check
        syntax_issues = CodeQualityChecker._check_syntax(code)
        issues.extend(syntax_issues)

        # Security checks
        security_issues = CodeQualityChecker._check_security(code)
        issues.extend(security_issues)

        # Performance checks
        performance_issues = CodeQualityChecker._check_performance(code)
        issues.extend(performance_issues)

        # Style and best practices
        style_issues = CodeQualityChecker._check_style(code)
        issues.extend(style_issues)

        # Logic and error handling
        logic_issues = CodeQualityChecker._check_logic(code)
        issues.extend(logic_issues)

        return issues

    @staticmethod
    def _check_syntax(code: str) -> List[CodeQualityIssue]:
        """Check for syntax errors and basic structure issues."""
        issues = []

        try:
            # Remove Jinja templating patterns before syntax checking to avoid false positives
            jinja_patterns = [
                r'\{\{[^}]*\}\}',  # Jinja2 variable templates
                r'\{%[^%]*%\}',    # Jinja2 control structures
            ]
            
            clean_code = code
            for pattern in jinja_patterns:
                clean_code = re.sub(pattern, '""', clean_code)
            
            ast.parse(clean_code)
        except SyntaxError as e:
            # Only report syntax errors that aren't related to Jinja templating
            if '{{' not in code or '}}' not in code:
                issues.append(CodeQualityIssue(
                    severity='error',
                    category='syntax',
                    message=f'Syntax error: {e.msg}',
                    line_number=e.lineno,
                    suggestion='Fix the syntax error in the Python code'
                ))
            else:
                # It's likely a Jinja templating issue, provide more helpful guidance
                issues.append(CodeQualityIssue(
                    severity='info',
                    category='syntax',
                    message='Template syntax detected - ensure Jinja templates are properly formatted',
                    line_number=e.lineno,
                    suggestion='Check Jinja2 template syntax for proper quoting'
                ))
        except Exception as e:
            issues.append(CodeQualityIssue(
                severity='error',
                category='syntax',
                message=f'Code parsing error: {str(e)}',
                suggestion='Ensure the code is valid Python syntax'
            ))

        return issues

    @staticmethod
    def _check_security(code: str) -> List[CodeQualityIssue]:
        """Check for security vulnerabilities."""
        issues = []

        # Check for dangerous patterns
        dangerous_patterns = [
            (r'eval\s*\(', 'Use of eval() is dangerous and should be avoided'),
            (r'exec\s*\(', 'Use of exec() is dangerous and should be avoided'),
            (r'__import__\s*\(', 'Direct __import__ usage may be unsafe'),
            (r'os\.system\s*\(', 'os.system() can be unsafe, consider subprocess'),
            (r'subprocess\.call\s*\(\s*\[.*\]\s*\)', 'subprocess.call without shell=False may be unsafe'),
        ]
        
        # Skip Jinja templating patterns from syntax checking
        jinja_patterns = [
            r'\{\{.*\}\}',  # Jinja2 templates
            r'\{%.*%\}',    # Jinja2 control structures
        ]
        
        # Remove Jinja patterns before syntax checking to avoid false positives
        clean_code = code
        for pattern in jinja_patterns:
            clean_code = re.sub(pattern, '""', clean_code)

        for pattern, message in dangerous_patterns:
            if re.search(pattern, code):
                issues.append(CodeQualityIssue(
                    severity='error',
                    category='security',
                    message=message,
                    suggestion='Use safer alternatives or validate inputs carefully'
                ))

        # Check for hardcoded secrets
        secret_patterns = [
            r'password\s*=\s*[\'"][^\'"]*[\'"]',
            r'secret\s*=\s*[\'"][^\'"]*[\'"]',
            r'key\s*=\s*[\'"][^\'"]*[\'"]',
            r'token\s*=\s*[\'"][^\'"]*[\'"]'
        ]

        for pattern in secret_patterns:
            if re.search(pattern, code, re.IGNORECASE):
                issues.append(CodeQualityIssue(
                    severity='warning',
                    category='security',
                    message='Potential hardcoded secret detected',
                    suggestion='Use Airflow Variables or secure credential storage'
                ))

        return issues

    @staticmethod
    def _check_performance(code: str) -> List[CodeQualityIssue]:
        """Check for performance issues."""
        issues = []

        # Check for inefficient patterns
        if re.search(r'for.*in.*range.*len.*:', code):
            issues.append(CodeQualityIssue(
                severity='warning',
                category='performance',
                message='Possible inefficient iteration pattern detected',
                suggestion='Consider using enumerate() or direct iteration'
            ))

        # Check for large data structures in memory
        if 'read()' in code and 'close()' not in code:
            issues.append(CodeQualityIssue(
                severity='warning',
                category='performance',
                message='File opened but not explicitly closed',
                suggestion='Use context managers (with statement) for file operations'
            ))

        return issues

    @staticmethod
    def _check_style(code: str) -> List[CodeQualityIssue]:
        """Check for style and readability issues."""
        issues = []

        # Check line length (rough estimate)
        lines = code.split('\n')
        for i, line in enumerate(lines, 1):
            if len(line) > 100:
                issues.append(CodeQualityIssue(
                    severity='info',
                    category='style',
                    message=f'Line {i} is {len(line)} characters long',
                    line_number=i,
                    suggestion='Consider breaking long lines for better readability'
                ))

        # Check for proper indentation
        if re.search(r'^\s*\t', code, re.MULTILINE):
            issues.append(CodeQualityIssue(
                severity='warning',
                category='style',
                message='Mixed tabs and spaces detected',
                suggestion='Use consistent 4-space indentation'
            ))

        # Check for descriptive variable names
        if re.search(r'\b[a-zA-Z]\b\s*=', code):  # Single letter variables
            issues.append(CodeQualityIssue(
                severity='info',
                category='style',
                message='Single-letter variable names detected',
                suggestion='Use more descriptive variable names'
            ))

        return issues

    @staticmethod
    def _check_logic(code: str) -> List[CodeQualityIssue]:
        """Check for logical issues and error handling."""
        issues = []

        # Check for missing error handling
        if 'try:' not in code and ('open(' in code or 'connect' in code or 'requests' in code):
            issues.append(CodeQualityIssue(
                severity='warning',
                category='logic',
                message='IO operation without error handling detected',
                suggestion='Add try/except blocks around IO operations'
            ))

        # Check for missing logging
        if ('print(' in code or 'logging.' in code) and not ('logger.' in code or 'logging.' in code):
            issues.append(CodeQualityIssue(
                severity='info',
                category='logic',
                message='Consider using proper logging instead of print statements',
                suggestion='Use logging module for better monitoring and debugging'
            ))

        # Check for obvious unreachable code patterns (simple cases only)
        # This is a simplified check to avoid false positives with try/except blocks
        if re.search(r'return.*\n\s*[a-zA-Z_][a-zA-Z0-9_]*\s*=', code, re.MULTILINE):
            # Variable assignment after return - likely unreachable
            issues.append(CodeQualityIssue(
                severity='warning',
                category='logic',
                message='Variable assignment after return statement may be unreachable',
                suggestion='Move variable assignment before return or restructure logic'
            ))
        elif re.search(r'return.*\n\s*print\s*\(', code, re.MULTILINE):
            # Print statement after return - definitely unreachable
            issues.append(CodeQualityIssue(
                severity='warning',
                category='logic',
                message='Print statement after return is unreachable',
                suggestion='Move print statement before return'
            ))

        return issues

    @staticmethod
    def analyze_dag_tasks(tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analyze all tasks in a DAG and provide comprehensive quality assessment.

        Args:
            tasks: List of task specifications from DAG spec

        Returns:
            Dict with quality analysis results
        """
        all_issues = []
        task_analyses = {}

        for task in tasks:
            task_id = task.get('task_id', 'unknown')
            python_code = task.get('python_code', '')
            bash_command = task.get('bash_command', '')

            task_issues = []

            # Analyze Python code
            if python_code:
                python_issues = CodeQualityChecker.analyze_python_code(python_code, task_id)
                task_issues.extend(python_issues)

            # Analyze bash commands
            if bash_command:
                bash_issues = CodeQualityChecker._analyze_bash_command(bash_command, task_id)
                task_issues.extend(bash_issues)

            # Store task-specific analysis
            task_analyses[task_id] = {
                'issues': [CodeQualityChecker._issue_to_dict(issue) for issue in task_issues],
                'quality_score': CodeQualityChecker.get_quality_score(task_issues)
            }

            all_issues.extend(task_issues)

        # Overall DAG quality assessment
        overall_score = CodeQualityChecker.get_quality_score(all_issues)

        return {
            'overall_quality': overall_score,
            'task_analyses': task_analyses,
            'total_issues': len(all_issues),
            'issues_by_severity': {
                'errors': len([i for i in all_issues if i.severity == 'error']),
                'warnings': len([i for i in all_issues if i.severity == 'warning']),
                'info': len([i for i in all_issues if i.severity == 'info'])
            },
            'recommendations': CodeQualityChecker._generate_recommendations(all_issues)
        }

    @staticmethod
    def _analyze_bash_command(command: str, task_id: str) -> List[CodeQualityIssue]:
        """Analyze bash command quality."""
        issues = []

        # Check for dangerous commands
        dangerous_commands = ['rm -rf /', 'dd if=', 'mkfs', 'fdisk']
        for dangerous in dangerous_commands:
            if dangerous in command:
                issues.append(CodeQualityIssue(
                    severity='error',
                    category='security',
                    message=f'Dangerous command detected: {dangerous}',
                    suggestion='Review and validate this command carefully'
                ))

        # Check for proper error handling (be more lenient)
        has_error_handling = ('&&' in command or '||' in command or
                             'set -e' in command or 'if' in command or
                             'trap' in command or 'try' in command)

        # Only warn if there are multiple commands and no error handling
        command_count = command.count(';') + command.count('|') + command.count('&&') + command.count('||') + 1
        if command_count > 1 and not has_error_handling and not command.strip().startswith('echo'):
            issues.append(CodeQualityIssue(
                severity='info',  # Changed from warning to info for simple cases
                category='logic',
                message='Bash command could benefit from error handling',
                suggestion='Consider adding && or || for error checking'
            ))

        return issues

    @staticmethod
    def _issue_to_dict(issue: CodeQualityIssue) -> Dict[str, Any]:
        """Convert CodeQualityIssue to dictionary."""
        return {
            'severity': issue.severity,
            'category': issue.category,
            'message': issue.message,
            'line_number': issue.line_number,
            'suggestion': issue.suggestion
        }

    @staticmethod
    def _generate_recommendations(issues: List[CodeQualityIssue]) -> List[str]:
        """Generate actionable recommendations based on issues."""
        recommendations = []

        # Group issues by category
        categories = {}
        for issue in issues:
            if issue.category not in categories:
                categories[issue.category] = []
            categories[issue.category].append(issue)

        # Generate category-specific recommendations
        if 'security' in categories:
            recommendations.append("ðŸ”’ Address security issues: Use Airflow Variables for sensitive data and avoid dangerous operations")

        if 'logic' in categories:
            recommendations.append("ðŸ”§ Improve error handling: Add try/except blocks and proper logging to all tasks")

        if 'performance' in categories:
            recommendations.append("âš¡ Optimize performance: Use context managers for file operations and avoid memory-intensive patterns")

        if 'style' in categories:
            recommendations.append("ðŸ“ Improve code style: Use descriptive variable names and consistent formatting")

        if not recommendations:
            recommendations.append("âœ… Code quality looks good! Consider adding more comprehensive error handling for production use.")

        return recommendations

    @staticmethod
    def get_quality_score(issues: List[CodeQualityIssue]) -> Dict[str, Any]:
        """Calculate overall quality score from issues."""
        if not issues:
            return {
                'score': 100,
                'grade': 'A',
                'issues_count': 0,
                'critical_issues': 0
            }

        # Weight issues by severity
        weights = {
            'error': 10,
            'warning': 5,
            'info': 1
        }

        total_penalty = sum(weights.get(issue.severity, 1) for issue in issues)
        critical_issues = len([i for i in issues if i.severity == 'error'])

        # Calculate score (max 100, min 0)
        score = max(0, 100 - total_penalty)

        # Determine grade
        if score >= 90:
            grade = 'A'
        elif score >= 80:
            grade = 'B'
        elif score >= 70:
            grade = 'C'
        elif score >= 60:
            grade = 'D'
        else:
            grade = 'F'

        return {
            'score': score,
            'grade': grade,
            'issues_count': len(issues),
            'critical_issues': critical_issues,
            'breakdown': {
                'errors': len([i for i in issues if i.severity == 'error']),
                'warnings': len([i for i in issues if i.severity == 'warning']),
                'info': len([i for i in issues if i.severity == 'info'])
            }
        }
